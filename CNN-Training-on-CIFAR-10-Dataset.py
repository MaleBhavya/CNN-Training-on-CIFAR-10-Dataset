# -*- coding: utf-8 -*-
"""PA4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QH33iPfxORN7OBnm-Wq2AJGmMR-ntCCL
"""

import torch  # PyTorch library for deep learning
import torchvision  # For popular datasets and model architectures
import torchvision.transforms as transforms  # Tools for image preprocessing
import torch.nn as nn  # For creating neural network layers
import numpy as np  # Library for numerical operations
import matplotlib.pyplot as plt  # For plotting training/testing metrics
import argparse  # For parsing command-line arguments


class CNNModel(nn.Module):
    def __init__(self, architecture_type):
        """
        Initialize the CNN model with two architecture options.
        Args:
            architecture_type (int): Specify architecture (1 or 2).
        """
        super(CNNModel, self).__init__()  # Call parent class (nn.Module) constructor

        # Define convolutional layers
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)  # First conv layer: 3 -> 16 channels
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  # Second conv layer: 16 -> 32 channels
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Third conv layer: 32 -> 64 channels
        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # Fourth conv layer (for mode 2): 64 -> 128

        # Define fully connected (dense) layers
        self.fc1 = nn.Linear(64 * 4 * 4, 240)  # First dense layer: Input from pooled feature maps
        self.fc2 = nn.Linear(240, 84)  # Second dense layer
        self.fc3 = nn.Linear(84, 10)  # Third dense layer: Output layer for 10 classes
        self.fc_extra = nn.Linear(128 * 2 * 2, 240)  # Additional dense layer for mode 2

        # Pooling, activation, and dropout layers
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)  # Max-pooling to reduce spatial dimensions
        self.relu = nn.ReLU()  # ReLU activation for non-linearity
        self.softmax = nn.Softmax(dim=1)  # Softmax for converting outputs to probabilities
        self.dropout = nn.Dropout(p=0.5)  # Dropout for regularization (prevent overfitting)

        # Select architecture based on input parameter
        if architecture_type == 1:
            self.forward = self.architecture_one  # Mode 1: 3 conv layers
        elif architecture_type == 2:
            self.forward = self.architecture_two  # Mode 2: 4 conv layers
        else:
            raise ValueError("Architecture type must be 1 or 2.")

    def architecture_one(self, inputs):
        """
        Forward pass for the first architecture: 3 convolutional layers + 3 fully connected layers.
        Args:
            inputs (torch.Tensor): Input tensor.
        Returns:
            torch.Tensor: Output probabilities.
        """
        x = self.maxpool(self.relu(self.conv1(inputs)))  # Conv1 -> ReLU -> MaxPool
        x = self.maxpool(self.relu(self.conv2(x)))  # Conv2 -> ReLU -> MaxPool
        x = self.maxpool(self.relu(self.conv3(x)))  # Conv3 -> ReLU -> MaxPool
        x = x.view(x.size(0), -1)  # Flatten feature maps into a 1D tensor
        x = self.dropout(self.relu(self.fc1(x)))  # Fully connected layer 1 -> ReLU -> Dropout
        x = self.dropout(self.relu(self.fc2(x)))  # Fully connected layer 2 -> ReLU -> Dropout
        x = self.softmax(self.fc3(x))  # Output layer -> Softmax
        return x

    def architecture_two(self, inputs):
        """
        Forward pass for the second architecture: 4 convolutional layers + 3 fully connected layers.
        Args:
            inputs (torch.Tensor): Input tensor.
        Returns:
            torch.Tensor: Output probabilities.
        """
        x = self.maxpool(self.relu(self.conv1(inputs)))  # Conv1 -> ReLU -> MaxPool
        x = self.maxpool(self.relu(self.conv2(x)))  # Conv2 -> ReLU -> MaxPool
        x = self.maxpool(self.relu(self.conv3(x)))  # Conv3 -> ReLU -> MaxPool
        x = self.maxpool(self.relu(self.conv4(x)))  # Conv4 -> ReLU -> MaxPool (extra layer for mode 2)
        x = x.view(x.size(0), -1)  # Flatten feature maps
        x = self.dropout(self.relu(self.fc_extra(x)))  # Additional dense layer for mode 2
        x = self.dropout(self.relu(self.fc2(x)))  # Fully connected layer 2 -> ReLU -> Dropout
        x = self.softmax(self.fc3(x))  # Output layer -> Softmax
        return x


def train_epoch(model, device, loader, optimizer, criterion):
    """
    Perform one training epoch.
    Args:
        model (nn.Module): The model to train.
        device (torch.device): Device to run the training on.
        loader (DataLoader): DataLoader for training data.
        optimizer (Optimizer): Optimizer for weight updates.
        criterion (Loss): Loss function.
    Returns:
        tuple: Average training loss and accuracy.
    """
    model.train()  # Set model to training mode
    epoch_loss = []  # List to store batch losses
    correct = 0  # Counter for correct predictions

    for images, labels in loader:  # Loop through batches
        images, labels = images.to(device), labels.to(device)  # Move data to the specified device
        optimizer.zero_grad()  # Reset gradients
        predictions = model(images)  # Forward pass
        loss = criterion(predictions, labels)  # Compute loss
        loss.backward()  # Backward pass to compute gradients
        optimizer.step()  # Update model weights

        epoch_loss.append(loss.item())  # Append batch loss
        correct += predictions.argmax(dim=1).eq(labels).sum().item()  # Count correct predictions

    average_loss = np.mean(epoch_loss)  # Calculate average loss
    accuracy = 100.0 * correct / len(loader.dataset)  # Calculate accuracy
    return average_loss, accuracy


def evaluate_model(model, device, loader, criterion):
    """
    Evaluate the model on test data.
    Args:
        model (nn.Module): The model to evaluate.
        device (torch.device): Device to run the evaluation on.
        loader (DataLoader): DataLoader for test data.
        criterion (Loss): Loss function.
    Returns:
        tuple: Average loss and accuracy.
    """
    model.eval()  # Set model to evaluation mode
    eval_loss = []  # List to store batch losses
    correct = 0  # Counter for correct predictions

    with torch.no_grad():  # Disable gradient computation for evaluation
        for images, labels in loader:  # Loop through batches
            images, labels = images.to(device), labels.to(device)  # Move data to the specified device
            predictions = model(images)  # Forward pass
            loss = criterion(predictions, labels)  # Compute loss
            eval_loss.append(loss.item())  # Append batch loss
            correct += predictions.argmax(dim=1).eq(labels).sum().item()  # Count correct predictions

    average_loss = np.mean(eval_loss)  # Calculate average loss
    accuracy = 100.0 * correct / len(loader.dataset)  # Calculate accuracy
    return average_loss, accuracy


def main(config):
    """
    Main function to set up the model, train, and evaluate.
    Args:
        config (Namespace): Configuration parameters.
    """
    # Select device for training (GPU if available, else CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Initialize model, loss function, and optimizer
    model = CNNModel(config.architecture_type).to(device)  # Create the model with the selected architecture
    criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification
    optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)  # Optimizer for updating weights

    # Define data transformations (e.g., normalization)
    transform = transforms.Compose([
        transforms.ToTensor(),  # Convert image to PyTorch tensor
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  # Normalize image channels
    ])

    # Load CIFAR-10 dataset
    train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

    # Create DataLoaders for batch processing
    train_loader = torch.utils.data.DataLoader(train_data, batch_size=config.batch_size, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_data, batch_size=config.batch_size, shuffle=False)

    # Initialize lists to store metrics for plotting
    train_losses, train_accuracies, test_losses, test_accuracies = [], [], [], []

    # Train the model for the specified number of epochs
    for epoch in range(1, config.epochs + 1):
        print(f"\nEpoch {epoch}/{config.epochs}")

        # Perform training for one epoch
        train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion)
        print(f"Training - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%")

        # Evaluate the model on the test dataset
        test_loss, test_acc = evaluate_model(model, device, test_loader, criterion)
        print(f"Testing  - Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%")

        # Append metrics for later plotting
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        test_losses.append(test_loss)
        test_accuracies.append(test_acc)

    # Plot training and testing loss
    plt.figure()
    plt.plot(range(1, config.epochs + 1), train_losses, label="Train Loss")
    plt.plot(range(1, config.epochs + 1), test_losses, label="Test Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training and Testing Loss")
    plt.legend()
    plt.savefig("loss_plot.png")
    plt.show()

    # Plot training and testing accuracy
    plt.figure()
    plt.plot(range(1, config.epochs + 1), train_accuracies, label="Train Accuracy")
    plt.plot(range(1, config.epochs + 1), test_accuracies, label="Test Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.title("Training and Testing Accuracy")
    plt.legend()
    plt.savefig("accuracy_plot.png")
    plt.show()

    # Print the best accuracy achieved
    print(f"\nBest Test Accuracy: {max(test_accuracies):.2f}%")


if __name__ == "__main__":
    import sys

    if "ipykernel" in sys.modules:  # Check if running in an interactive environment
        class Config:
            architecture_type = 1  # Default architecture type
            learning_rate = 0.1  # Default learning rate
            batch_size = 100  # Default batch size
            epochs = 30  # Default number of epochs

        config = Config()
    else:
        # For command-line execution
        parser = argparse.ArgumentParser(description="Train and evaluate CNN model")
        parser.add_argument("--architecture_type", type=int, default=1, help="Specify architecture (1 or 2)")
        parser.add_argument("--learning_rate", type=float, default=0.1, help="Learning rate")
        parser.add_argument("--batch_size", type=int, default=100, help="Batch size")
        parser.add_argument("--epochs", type=int, default=30, help="Number of epochs")
        config = parser.parse_args()

    # Call the main function with the configuration
    main(config)